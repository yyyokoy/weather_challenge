{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Fine-tune PredNet model trained for t+1 prediction for up to t+5 prediction.\n",
    "'''\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "\n",
    "from src.prednet import PredNet\n",
    "from src.data_utils import SequenceGenerator\n",
    "\n",
    "\n",
    "DATA_DIR = '../data/features'\n",
    "WEIGHTS_DIR = '../data/sat_weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss as MAE of frame predictions after t=0\n",
    "# It doesn't make sense to compute loss on error representation, since the error isn't wrt ground truth when extrapolating.\n",
    "def extrap_loss(y_true, y_hat):\n",
    "    y_true = y_true[:, 1:]\n",
    "    y_hat = y_hat[:, 1:]\n",
    "    return 0.5 * K.mean(K.abs(y_true - y_hat), axis=-1)  # 0.5 to match scale of loss when trained in error mode (positive and negative errors split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = 25\n",
    "extrap_start_time = 24  # starting at this time step, the prediction from the previous time step will be treated as the actual input\n",
    "orig_weights_file = os.path.join(WEIGHTS_DIR, 'prednet_sat_weights.hdf5')  # original t+1 weights\n",
    "orig_json_file = os.path.join(WEIGHTS_DIR, 'prednet_sat_model.json')\n",
    "\n",
    "save_model = True\n",
    "extrap_weights_file = os.path.join(WEIGHTS_DIR, 'prednet_sat_weights-extrapfinetuned.hdf5')  # where new weights will be saved\n",
    "extrap_json_file = os.path.join(WEIGHTS_DIR, 'prednet_sat_model-extrapfinetuned.json')\n",
    "\n",
    "# Data files\n",
    "train_file = os.path.join(DATA_DIR, 'X_train.hkl')\n",
    "train_sources = os.path.join(DATA_DIR, 'sources_train.hkl')\n",
    "val_file = os.path.join(DATA_DIR, 'X_val.hkl')\n",
    "val_sources = os.path.join(DATA_DIR, 'sources_val.hkl')\n",
    "\n",
    "# Training parameters\n",
    "nb_epoch = 2\n",
    "batch_size = 4\n",
    "samples_per_epoch = 500\n",
    "N_seq_val = 100  # number of sequences to use for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load t+1 model\n",
    "f = open(orig_json_file, 'r')\n",
    "json_string = f.read()\n",
    "f.close()\n",
    "orig_model = model_from_json(json_string, custom_objects = {'PredNet': PredNet})\n",
    "orig_model.load_weights(orig_weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 2, 48)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_model.layers[1].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_config = orig_model.layers[1].get_config()\n",
    "layer_config['output_mode'] = 'prediction'\n",
    "layer_config['extrap_start_time'] = extrap_start_time\n",
    "data_format = layer_config['data_format'] if 'data_format' in layer_config else layer_config['dim_ordering']\n",
    "prednet = PredNet(weights=orig_model.layers[1].get_weights(), **layer_config)\n",
    "\n",
    "input_shape = list(orig_model.layers[0].batch_input_shape[1:])\n",
    "input_shape[0] = nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "print(len(orig_model.layers[1].get_weights()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(input_shape)\n",
    "predictions = prednet(inputs)\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss=extrap_loss, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = SequenceGenerator(train_file, train_sources, nt, batch_size=batch_size, shuffle=True, output_mode='prediction')\n",
    "val_generator = SequenceGenerator(val_file, val_sources, nt, batch_size=batch_size, N_seq=N_seq_val, output_mode='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/2\n",
      "125/125 [==============================] - 114s 913ms/step - loss: 0.0255 - val_loss: 0.0273\n",
      "Epoch 2/2\n",
      "125/125 [==============================] - 108s 862ms/step - loss: 0.0249 - val_loss: 0.0272\n"
     ]
    }
   ],
   "source": [
    "lr_schedule = lambda epoch: 0.001 if epoch < 75 else 0.0001    # start with lr of 0.001 and then drop to 0.0001 after 75 epochs\n",
    "callbacks = [LearningRateScheduler(lr_schedule)]\n",
    "if save_model:\n",
    "    if not os.path.exists(WEIGHTS_DIR): os.mkdir(WEIGHTS_DIR)\n",
    "    callbacks.append(ModelCheckpoint(filepath=extrap_weights_file, monitor='val_loss', save_best_only=True))\n",
    "history = model.fit_generator(train_generator, samples_per_epoch / batch_size, nb_epoch, callbacks=callbacks,\n",
    "                validation_data=val_generator, validation_steps=N_seq_val / batch_size)\n",
    "\n",
    "if save_model:\n",
    "    json_string = model.to_json()\n",
    "    with open(extrap_json_file, \"w\") as f:\n",
    "        f.write(json_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
